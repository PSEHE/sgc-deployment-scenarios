"""
This will perform the data cleaning needed to load in blockgroup specific
metrics of population vulnerabilities.
"""

import pandas as pd
import geopandas as gpd
import geopandas as gpd
import fiona
import numpy as np

def get_vulnerability_data(GISJOIN,data_source = "CalEnviroScreen_blockgroup",
                            vulnerability_column = "SCORE_PCTL_CI_BG"):
    # Derived by selecting cols from CES, NRI spatial join csv, which is too large to push to github
    """
    Returns a dataframe indexed by GISJOIN with a column of the vulnerability metric
    of interest.

    Following are columns that contain some sort of score for CalEnviroScreen...

    CIscore,Ozone,PM2_5,DieselPM,Pesticide,Tox_Rel,Traffic,DrinkWat,Lead,Cleanup,
    GWThreat,HazWaste,ImpWatBod,SolWaste,PollBurd,PolBurdSc,Asthma,LowBirtWt,
    Cardiovas,Educatn,Ling_Isol,Poverty,Unempl,HousBurd,PopChar,PopCharSc,
    Child_10,Pop_10_64,Elderly65
    """
    vulnerability_df = pd.DataFrame(index = GISJOIN)
    # CalEnviroScreen uses the simple geoid formula State+County+tract = 2+3+6
    # GISjoin is different, so annoying! The "Tract" column translates GISJOIN to that GEOID numeric value
    vulnerability_df["Tract"] = [int(bg[1:3] + bg[4:7] + bg[8:14]) for bg in GISJOIN]

    if data_source == "CalEnviroScreen":
        calenviroscreen_gdf = gpd.read_file("/home/yunuskink/Documents/GitHub/sgc-deployment-scenarios/data/calenviroscreen40shpf2021shp.zip")
        vulnerability_df = vulnerability_df.merge(calenviroscreen_gdf[["Tract",vulnerability_column]],on = "Tract")

    elif data_source == "NRI": # National Risk Index
        nri_df = gpd.read_file("/home/yunuskink/Data/NRI_Shapefile_CensusTracts(1).zip")
        nri_df.drop(nri_df[nri_df["STATEFIPS"]!='06'].index,inplace=True)
        nri_df["Tract"] = int(nri_df["TRACTFIPS"])
        vulnerability_df = vulnerability_df.merge(nri_df[["Tract",vulnerability_column]],on = "Tract")
    elif data_source == "CalEnviroScreen_blockgroup":
        bg_ces_df = pd.read_csv('data/bg_ca_19/bg19_ces_indicators.csv')
        pct_cols = ['PCT_LESSHS', 'PCT_UNEMP', 'PCT_RENT', 'PCT_LINGISO', 'PCT_POV', 'RATE_ASTH', 'RATE_LBW', 'RATE_CVD']
        for pct_col in pct_cols:
            pctl_col = 'PCTL_' + pct_col.split('_')[1]
            bg_ces_df[pctl_col] = 100*bg_ces_df[pct_col].rank(pct = True)

        senspop_cols = ['PCTL_ASTH', 'PCTL_CVD', 'PCTL_LBW']
        ses_cols = ['PCTL_LESSHS', 'PCTL_UNEMP', 'PCTL_RENT', 'PCTL_LINGISO', 'PCTL_POV']
        bg_ces_df['SCORE_SENSPOP'] = bg_ces_df[senspop_cols].mean(axis = 1)
        bg_ces_df['SCORE_SES'] = bg_ces_df[ses_cols].mean(axis = 1)
        bg_ces_df['SCORE_POP'] = bg_ces_df[['SCORE_SES', 'SCORE_SENSPOP']].mean(axis = 1)/10
        bg_ces_df['SCORE_CI_BG'] = bg_ces_df['SCORE_POP']*bg_ces_df['SCORE_POLLUT']
        bg_ces_df['SCORE_PCTL_CI_BG'] = 100*bg_ces_df['SCORE_CI_BG'].rank(pct = True)
        vulnerability_df = vulnerability_df.merge(bg_ces_df[["GISJOIN",vulnerability_column]],left_index = True, right_on = "GISJOIN")

    elif data_source == "CalEPA":
        gpd.io.file.fiona.drvsupport.supported_drivers['KML'] = 'rw'
        df = gpd.read_file("/home/yunuskink/Downloads/Urban-Heat-Island-Map-CA.kmz",driver = "KML")
    # calenviroscreen_gdf["Tract"]
    # for col in calenviroscreen_gdf.columns:
    #     print(col)

    # bg_ces_df = pd.read_csv('data/bg_ca_19/bg19_ces_indicators.csv')
    # pct_cols = ['PCT_LESSHS', 'PCT_UNEMP', 'PCT_RENT', 'PCT_LINGISO', 'PCT_POV', 'RATE_ASTH', 'RATE_LBW', 'RATE_CVD']
    #
    # for pct_col in pct_cols:
    #
    #     pctl_col = 'PCTL_' + pct_col.split('_')[1]
    #     bg_ces_df[pctl_col] = 100*bg_ces_df[pct_col].rank(pct = True)
    #
    # senspop_cols = ['PCTL_ASTH', 'PCTL_CVD', 'PCTL_LBW']
    # ses_cols = ['PCTL_LESSHS', 'PCTL_UNEMP', 'PCTL_RENT', 'PCTL_LINGISO', 'PCTL_POV']
    #
    # bg_ces_df['SCORE_SENSPOP'] = bg_ces_df[senspop_cols].mean(axis = 1)
    # bg_ces_df['SCORE_SES'] = bg_ces_df[ses_cols].mean(axis = 1)
    # bg_ces_df['SCORE_POP'] = bg_ces_df[['SCORE_SES', 'SCORE_SENSPOP']].mean(axis = 1)/10
    #
    # bg_ces_df['SCORE_CI_BG'] = bg_ces_df['SCORE_POP']*bg_ces_df['SCORE_POLLUT']
    # bg_ces_df['SCORE_PCTL_CI_BG'] = 100*bg_ces_df['SCORE_CI_BG'].rank(pct = True)
    #
    # bg_ces_df = bg_ces_df.loc[:, ['GISJOIN', 'SCORE_PCTL_CI_BG']]
    #
    # bg_ces_dict = {bg_ces_df.iloc[row]['GISJOIN']: round(0.01*bg_ces_df.iloc[row]['SCORE_PCTL_CI_BG'], 2) for row in bg_ces_df.index}
    vulnerability_df.set_index("GISJOIN",inplace=True)
    return vulnerability_df
